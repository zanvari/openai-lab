{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4bc1e9",
   "metadata": {},
   "source": [
    "# üëÅÔ∏è GPT-4o Vision Example: Image + Prompt\n",
    "\n",
    "Explore how to send images and text together to GPT-4o for multimodal reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dacf83",
   "metadata": {},
   "source": [
    "## üîß Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e177425",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai Pillow --quiet\n",
    "import openai\n",
    "import os\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"sk-...\")  # Replace or load from .env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa0ae6",
   "metadata": {},
   "source": [
    "## üì• Upload an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd6549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload or load your image (replace this with your image path)\n",
    "image_path = \"example.jpg\"  # Or use Colab's upload widget\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Convert image to base64\n",
    "buffer = BytesIO()\n",
    "image.save(buffer, format=\"JPEG\")\n",
    "img_b64 = base64.b64encode(buffer.getvalue()).decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95cb3b",
   "metadata": {},
   "source": [
    "## ü§ñ Ask a Visual Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is happening in this image?\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{img_b64}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34478abb",
   "metadata": {},
   "source": [
    "## üß† Prompt Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca67bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Describe this image like you're explaining it to a child.\",\n",
    "    \"Write a tweet about this image.\",\n",
    "    \"What are the key objects visible?\"\n",
    "]\n",
    "\n",
    "for p in prompts:\n",
    "    result = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": p},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_b64}\"}}\n",
    "            ]\n",
    "        }]\n",
    "    )\n",
    "    print(f\"üìù Prompt: {p}\\n{result.choices[0].message['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96ad90",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "- Loaded and encoded an image in base64\n",
    "- Sent image + prompt to GPT-4o\n",
    "- Tested multiple prompt styles\n",
    "- Got visual reasoning from the model"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
